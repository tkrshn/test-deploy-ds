# NOTE: The name of this application is org_all_app_props - this assumes
#        the application log files are the same across all departments.
#        If each department has their own format you should name the application
#        org_dept_app_props like the coordinating _inputs configuration bundle.

# This is a basic props.conf for an application log file.

# APPLICATION NAME

# Used for uploading one off files. Uploaded file must match the name listed in the source.
[source::....my_sourcetype]
sourcetype = my_sourcetype

# These configs are provided as a sample. The usual site-specific tweaks
# would lie within the TIME_PREFIX, and TIME_FORMAT.

[my_sourcetype]
TIME_PREFIX = ^
MAX_TIMESTAMP_LOOKAHEAD = 25
TZ = GMT
# A performance tweak is to disable SHOULD_LINEMERGE and then set the 
# LINE_BREAKER to "line ending characters coming before a new time stamp"
# (note the direct link of the TIME_FORMAT to the regex of LINE_BREAKER).
TIME_FORMAT = %Y-%m-%d %H:%M:%S,%3N
LINE_BREAKER = ([\r\n]+)\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2},\d{3}
SHOULD_LINEMERGE = False
# 10000 is default, should be set on a case by case basis
TRUNCATE = 10000

# If the data does not have nice key=value pairs, (or some other readily
# machine parseable format, like JSON or XML), set KV_MODE = none so that
# Splunk doesn't spin its wheels on attempting to look for key = value
# pairs which don't exist.
KV_MODE = None

# Leaving PUNCT enabled can impact indexing performance. Customers can
# comment this line if they need to use PUNCT (e.g. security use cases)
ANNOTATE_PUNCT = false
# Inline field extraction
# EXTRACT-connection_id = (?i)(connectionid|conn_id|callid)\=(?<connection_id>\d{6})
# Field extraction using a transforms.conf
# REPORT-auto_kv_for_all_fields = auto_kv_for_all_fields

########################################################################
# This sourcetype below is receiving lots of data from various devices all
# coming in as the same sourcetype. The data has to be re-sourcetyped to
# pick out specific devices based on regexes to brand them as the appropriate
# data type.
########################################################################
[composite_sourcetype]
# We still need time and line breaker configs on the *base* sourcetype,
# because transforms to change sourcetype, etc, come *after* time stamping.
TIME_PREFIX = ^
# This is consistent with a standard syslog prefix.
# See http://strftime.net for more examples.
TIME_FORMAT = %b %d %H:%M:%S
SHOULD_LINEMERGE = false

# These are sorted by what comes after the -, so these rules for null
# queueing would come first.
# NOTE: It's possible to "drop everything, save X Y Z" with a list of 
# transforms here.
TRANSFORMS-0_null_queue = org_drop_comments, org_save_special_comments
# This particular rule is "borrowed" from the default configs; these rules
# do not have to exist in this application context, just be visible here.
TRANSFORMS-1_fix_hostname = syslog-host
# You get one pass through these, left to right. Parsing rules on the
# *new* sourcetype *are not* called, only search-time props (such as
# EXTRACT or REPORT) would be leveraged.
TRANSFORMS-2_fix_sourcetype = org_sourcetype_cisco, org_sourcetype_juniper, org_sourcetype_sshd
# Now, based on the other rules above, we can also change the destination index.
# Note that the last rule to set a value wins, if data has sourcetype cisco,
# yet is for a host called 'fw309', the last transform will force it into the
# DMZ index, regardless that the rest of the Cisco data wants to go to the
# network index (see: transforms.conf)
TRANSFORMS-3_fix_index = org_sourcetype_cisco_index, org_sourcetype_juniper_index, org_host_fw309-dmz_index

# Make the private data into something hidden.
SEDCMD-elide_SSN = s/\d{3}-\d{2}-\d{4}/xxx-xx-xxxx/g

